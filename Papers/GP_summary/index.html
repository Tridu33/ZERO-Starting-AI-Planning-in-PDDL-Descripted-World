<!DOCTYPE html><html> <head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width, initial-scale=1.0"><meta name=author content=tridu33><link rel="shortcut icon" href=../../img/favicon.ico><title>GP_summary &mdash; AI Planning in PDDL-Descripted World</title><link rel=stylesheet href="//fonts.googleapis.com/css?family=Lato:400,700"><link rel=stylesheet href=//cdn.jsdelivr.net/gh/tonsky/FiraCode@1.206/distr/fira_code.css><link rel=stylesheet href=//use.fontawesome.com/releases/v5.8.1/css/all.css><link rel=stylesheet href=//use.fontawesome.com/releases/v5.8.1/css/v4-shims.css><link rel=stylesheet href=../../css/theme.css><link rel=stylesheet href=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css><script src=//code.jquery.com/jquery-2.1.1.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/yaml.min.js></script><script src=//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/languages/python.min.js></script><script>
        hljs.initHighlightingOnLoad();
    </script></head> <body ontouchstart> <div id=container> <aside> <div class=home> <div class=title> <button class=hamburger></button> <a href=../.. class=site-name> AI Planning in PDDL-Descripted World</a> </div> <div class=search> <div role=search> <form id=rtd-search-form class=wy-form action=../../search.html method=get> <input type=text name=q placeholder="Search docs" title="Type search term here"> </form> </div> </div> </div> <nav class=nav> <ul class=root> <li class=toctree-l1><a class=nav-item href=../..>Home</a></li> <li class=toctree-l1><button class="section nav-item">规划界黑话</button> <ul class=subnav> <li class=toctree-l2><button class="section nav-item hide">PDDL进化史</button> <ul class="subnav hide"> <li class=toctree-l3><a href=../../PlanLanguages/ADL/ class=nav-item>ADL</a></li> <li class=toctree-l3><a href=../../PlanLanguages/STRIPS%E8%AF%AD%E8%A8%80/ class=nav-item>STRIPS</a></li> <li class=toctree-l3><button class="section nav-item hide">PDDL</button> <ul class="subnav hide"> <li class=toctree-l4><a href=../../PlanLanguages/PDDL%E8%AF%AD%E8%A8%80/ class=nav-item>HelloPDDL</a><a href=../../PlanLanguages/PDDL%E8%AF%AD%E8%A8%80/ class=nav-item>HelloPDDL</a></li> <li class=toctree-l4> <a href=../../PlanLanguages/version/ class=nav-item>版本迭代</a></li> <li class=toctree-l4><a href=../../PlanLanguages/Extension%20to%20PDDL%28SAS%29/ class=nav-item>PDDL扩展</a></li> </ul></li> </ul></li> <li class=toctree-l2><button class="section nav-item hide">机器人世界</button> <ul class="subnav hide"> <li class=toctree-l3><a href=../../PlanLanguages/Golog/Golog_ROS/ class=nav-item>Golog</a><a href=../../PlanLanguages/Golog/Golog_ROS/ class=nav-item>Golog</a><a href=../../PlanLanguages/Golog/Golog_ROS/ class=nav-item>Golog</a></li> </ul></li> </ul></li> <li class=toctree-l1><button class="section nav-item">PDDL使用</button> <ul class=subnav> <li class=toctree-l2> <a href=../../Usage/LocalSolvers/ class=nav-item>本地环境使用</a></li> <li class=toctree-l2> <a href=../../Usage/OnlineSolver/ class=nav-item>线上求解器使用</a></li> <li class=toctree-l2> <a href=../../Usage/VSCode/ class=nav-item>Visual Studio Code使用</a></li> <li class=toctree-l2><button class="section nav-item hide">经典demos</button> <ul class="subnav hide"> <li class=toctree-l3><a href=../../SolversBaseOnPDDL/%E5%88%8A%E7%89%A9%E4%B8%8A%E7%BB%8F%E5%85%B8demos/ class=nav-item>刊物上经典demos</a></li> <li class=toctree-l3><a href=../../SolversBaseOnPDDL/PDDL%20Benchmark%20Instances/ class=nav-item>BenchMark</a></li> </ul></li> </ul></li> <li class=toctree-l1><button class="section nav-item">PDDL语法</button> <ul class=subnav> <li class=toctree-l2> <a href=../../Syntax/PDDL%20axioms/ class=nav-item>语法总览</a></li> <li class=toctree-l2> <a href=../../Syntax/PDDLParser/ class=nav-item>Parser</a></li> </ul></li> <li class=toctree-l1><button class="section nav-item">PDDL-Descripted AI Planning World</button> <ul class=subnav> <li class="toctree-l2 current"><button class="section nav-item">Papers</button> <ul class=subnav> <li class=toctree-l3><a href=../A%20review%20of%20generalized%20planning/ class=nav-item>reviewOfGP</a></li> <li class="toctree-l3 current"><a href=./ class="nav-item current">GP_summary</a> <ul class=subnav> <li class=toctree-l4><a class="nav-item toc" href=#11>1.1. 经典问题例子</a></li> <li class=toctree-l4><a class="nav-item toc" href=#2-generalized-planning>2. Generalized planning通用规划</a></li> <li class=toctree-l4><a class="nav-item toc" href=#21>2.1. 自动规划</a></li> <li class=toctree-l4><a class="nav-item toc" href=#22-qnp>2.2. QNP</a></li> <li class=toctree-l4><a class="nav-item toc" href=#3>3. 结合逻辑神经机</a></li> <li class=toctree-l4><a class="nav-item toc" href=#32>3.2. 其他相关的论文书籍</a></li> </ul></li> <li class=toctree-l3><a href=../A%20Review%20of%20Machine%20Learning%20for%20Automated%20Planning/ class=nav-item>ReviewOfMLforAP</a></li> <li class=toctree-l3><a href=../Generalized%20Planning%20With%20Deep%20Reinforcement%20Learning/ class=nav-item>GPwithDeep-RL</a></li> <li class=toctree-l3><a href=../Survey%20of%20research%20literature/ class=nav-item>researchSurvey</a></li> </ul></li> <li class=toctree-l2><button class="section nav-item hide">SolversBaseOnPDDL</button> <ul class="subnav hide"> <li class=toctree-l3><a href=../../SolversBaseOnPDDL/PyperPlan_STRIPS/ class=nav-item>PyperPlan_STRIPS</a></li> <li class=toctree-l3><a href=../../SolversBaseOnPDDL/Solvers/ class=nav-item>Solvers</a></li> <li class=toctree-l3><button class="section nav-item hide">CP</button> <ul class="subnav hide"> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/CP/ffPlaner/ class=nav-item>FF</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/CP/fast-downward/ class=nav-item>FD</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/CP/LAPKT%E8%BD%BB%E9%87%8F%E8%87%AA%E5%8A%A8%E8%A7%84%E5%88%92%E5%B7%A5%E5%85%B7%E5%8C%85/ class=nav-item>LAPKT轻量自动规划工具包</a></li> </ul></li> <li class=toctree-l3><button class="section nav-item hide">GP_Numerical</button> <ul class="subnav hide"> <li class=toctree-l4> <a href=../../SolversBaseOnPDDL/GP_Numerical/QNP_ReduceTo_GraphProblem/ class=nav-item>QNP_ReduceTo_GraphProblem</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/%E5%9B%BE%E6%B3%95QNP/ class=nav-item>图法QNP</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/LPG%EF%BC%88%E6%9C%AC%E5%9C%B0%E6%90%9C%E7%B4%A2%E8%A7%84%E5%88%92%E5%9B%BE%EF%BC%89/ class=nav-item>LPG</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/grahPlan/ class=nav-item>grahPlan</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/SGPlan6/ class=nav-item>SGPlan6</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/PRP/ class=nav-item>PRP</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/myND/ class=nav-item>myND</a></li> </ul></li> <li class=toctree-l3><button class="section nav-item hide">QNP_FONS_SAT</button> <ul class="subnav hide"> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/QNP_FONS_SAT/CNF_py/ class=nav-item>CNF_py</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/QNP_FONS_SAT/FOND/ class=nav-item>FOND</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/QNP_FONS_SAT/QA_FOND/ class=nav-item>QA_FOND</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/QNP_FONS_SAT/%E4%BE%8B%E8%A7%A3FOND%2BCNF/ class=nav-item>例解FOND</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/QNP_FONS_SAT/QNP/ class=nav-item>QNP</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/QNP_FONS_SAT/qnp2fond/ class=nav-item>qnp2fond</a></li> <li class=toctree-l4><a href=../../SolversBaseOnPDDL/GP_Numerical/QNP_FONS_SAT/QNP2SAT/ class=nav-item>QNP2SAT</a></li> </ul></li> </ul></li> <li class=toctree-l2><button class="section nav-item hide">PDDL-plan-validators</button> <ul class="subnav hide"> <li class=toctree-l3><a href=../../Extensions/PDDL-plan-validator/PDDL-plan-validator/ class=nav-item>validators</a></li> <li class=toctree-l3><a href=../../Extensions/PDDL-plan-validator/Lisp-pddl-INVAL-validator/ class=nav-item>INVAL</a></li> <li class=toctree-l3><a href=../../Extensions/PDDL-plan-validator/VScode-PDDL%E6%8F%92%E4%BB%B6VAL/ class=nav-item>VAL</a></li> </ul></li> <li class=toctree-l2><button class="section nav-item hide">PDDL-Auto Planning</button> <ul class="subnav hide"> <li class=toctree-l3><a href=../../Extensions/AP/PDDL4j_Java%20for%E8%87%AA%E5%8A%A8%E8%A7%84%E5%88%92/ class=nav-item>PDDL4j</a></li> <li class=toctree-l3><a href=../../Extensions/AP/Tarski%20-%20An%20AI%20Planning%20Modeling%20Framework/ class=nav-item>Tarski</a><a href=../../Extensions/AP/Tarski%20-%20An%20AI%20Planning%20Modeling%20Framework/ class=nav-item>Tarski</a></li> <li class=toctree-l3><a href=../../Extensions/AP/%E5%AE%9E%E4%BE%8B%E4%B8%AD%E5%AD%A6%E4%B9%A0QNP%E5%AE%9A%E4%B9%89%E5%AE%9E%E7%8E%B0AP%28AutomatedPlanning%29/ class=nav-item>QNP2AP</a></li> <li class=toctree-l3><a href=../../Extensions/RL/PDDLGYM/ class=nav-item>PDDLGYM</a></li> <li class=toctree-l3><a href=../../Extensions/RL/RLPlanPapers/ class=nav-item>PDDL+RL强化学习</a></li> </ul></li> </ul></li> <li class=toctree-l1><button class="section nav-item">进击的PDDL</button> <ul class=subnav> <li class=toctree-l2><button class="section nav-item hide">Curry-Howard correspondence</button> <ul class="subnav hide"> <li class=toctree-l3><a href=../../FurtherMore/%E6%8E%A7%E5%88%B6%E6%B5%81%E5%9B%BECFG%E8%AF%AD%E4%B9%89%E7%BD%91%E7%BB%9Cpetri%E8%BF%81%E7%A7%BB%E7%B3%BB%E7%BB%9F%E6%89%A9%E5%B1%95%E5%BA%94%E7%94%A8/ class=nav-item>CFG语义网络</a></li> <li class=toctree-l3><a href=../../FurtherMore/PDDL-Solver2AST/ class=nav-item>PDDL-Solver2AST</a></li> <li class=toctree-l3><a href=../../FurtherMore/TransitionSystemModelCheck/ class=nav-item>CFG=TransitionSystemModelCheck.md</a></li> <li class=toctree-l3><a href=../../FurtherMore/qnp2ast2program/ class=nav-item>qnp2ast2program</a></li> </ul></li> </ul></li> <li class=toctree-l1> <a class=nav-item href=https://github.com/Tridu33/ZERO-Starting-AI-Planning-in-PDDL-Descripted-World/issues>Issue跟踪讨论</a></li> </ul> </nav> <div class=repo> <div class=link> </div> <div class=previous><a href=../A%20review%20of%20generalized%20planning/ >&laquo; Previous</a></div> <div class=next><a href=../A%20Review%20of%20Machine%20Learning%20for%20Automated%20Planning/ >Next &raquo;</a></div> </div> </aside> <div id=spacer><button class=arrow></button></div> <main> <div class=home-top> <button class=hamburger></button> <a href=../.. class=site-name> AI Planning in PDDL-Descripted World</a> </div> <div id=main> <nav class=breadcrumbs> <ul> <li>PDDL-Descripted AI Planning World &raquo; </li><li>Papers</li> </ul> </nav> <div id=content><div class=toc> <ul> <li><a href=#gp-summary>GP summary</a><ul> <li><a href=#11>1.1. 经典问题例子</a></li> <li><a href=#2-generalized-planning>2. Generalized planning通用规划</a></li> <li><a href=#21>2.1. 自动规划</a></li> <li><a href=#22-qnp>2.2. QNP</a></li> <li><a href=#3>3. 结合逻辑神经机</a><ul> <li><a href=#311-sat>3.1.1. SAT</a></li> <li><a href=#312-complexity>3.1.2. Complexity</a></li> </ul> </li> <li><a href=#32>3.2. 其他相关的论文书籍</a></li> </ul> </li> </ul> </div> <p><a href=https://zhuanlan.zhihu.com/p/259723540>Zotero + Web of Science，如何做文献泛读</a></p> <h1 id=gp-summary>GP summary<a class=headerlink href=#gp-summary title="Permanent link">&para;</a></h1> <h2 id=11>1.1. 经典问题例子<a class=headerlink href=#11 title="Permanent link">&para;</a></h2> <p>Aminof, B., Giacomo, G. D., Murano, A., &amp; Rubin, S. (2019). Planning under ltl environment specifications. In <em>Proc. ICAPS,</em> pp. 31-39.积木世界QNP实例</p> <p>Bonet, B., Frances, G., &amp; Geffner, H. (2019). Learning features and abstract actions for computing generalized plans. In Proc.AAAI.石头世界 <span class=arithmatex>\(Q_{clear}\)</span>和G ripper例子</p> <p>Bonet, B., &amp; Geffner, H. (2015). Policies that generalize: Solving many planning problems with the same policy.. In <em>IJCAI,</em> pp. 2798-2804.很多经典问题</p> <h2 id=2-generalized-planning>2. Generalized planning通用规划<a class=headerlink href=#2-generalized-planning title="Permanent link">&para;</a></h2> <p>Jimenez, S., Segovia-Aguas, J., &amp; Jonsson, A. (2019). <strong>综述A review of Generalized planning</strong>. <em>The Knowledge Engineering Review, 34.</em></p> <p>Aguas, J. S., Celorrio, S. J., , &amp; Jonsson, A. (2016). <strong>Generalized planning</strong> with procedural domain control knowledge. In <em>Proc. ICAPS.</em></p> <p>Belle, V., &amp; Levesque, H. J. (2016). Foundations for <strong>Generalized planning</strong> in unbounded stochastic domains. In <em>KR,</em> pp. 380-389.</p> <p>Bercher, P., &amp; Mattmuller, R. (2009). Solving non-deterministic planning problems with pattern database heuristics. In <em>Proc. German Conf. on AI (KI),</em> pp. 57-64. Springer.</p> <p>Bonet, B., Palacios, H., &amp; Geffner, H. (2009). Automatic derivation of memoryless policies and finite-state controllers using classical planners. In <em>Proc. ICAPS-09,</em> pp. 34-41.</p> <p>Bonet, B., De Giacomo, G., Geffner, H., &amp; Rubin, S. (2017). <strong>Generalized planning</strong>: Nondeterministic abstractions and trajectory constraints. In <em>Proc. IJCAI.</em></p> <p>Bonet, B., &amp; Geffner, H. (2018). Features, projections, and representation change for <strong>Generalized planning</strong>. In <em>Proceedings of the 27<sup>th</sup> International Joint Conference on Artificial Intelligence,</em> pp. 4667-4673. AAAI Press.把GP映射QNP求解</p> <p>Bonet, B., Palacios, H., &amp; Geffner, H. (2009). Automatic derivation of memoryless policies and finite-state controllers using classical planners. In <em>ICAPS</em>.</p> <p>Bueno, T. P., de Barros, L. N., Maua, D. D., &amp; Sanner,S. (2019). Deep reactive policies for planning in stochastic nonlinear domains. In <em>AAAI</em>, Vol. 33, pp. 7530-7537.</p> <p>Camacho, A., Bienvenu, M., &amp; McIlraith, S. A. (2019). Towards a unified view of ai planning and reactive synthesis. In <em>Proc. ICAPS,</em> pp. 58-67.</p> <p>Cimatti, A., Pistore, M., Roveri, M., &amp; Traverso, P. (2003). Weak, strong, and strong cyclic planning via symbolic model checking. <em>Artificial Intelligence, 147</em>(1-2), 35-84.****</p> <p>Fikes, R., &amp; Nilsson, N. (1971). STRIPS: A new approach to the application of theorem proving to problem solving. <em>Artificial Intelligence,</em> 1, 27-120.**紧凑描述STRIPS**规划语言</p> <p>Geffner, T., &amp; Geffner, H. (2018). Compact policies for fully observable non-deterministic planning as sat. In *Proc. ICAPS.*把FOND问题转换为SAT问题求解那个github源码程序包对应论文</p> <p>Hu, Y., &amp; De Giacomo, G. (2011). <strong>Generalized planning</strong>: Synthesizing plans that work for multiple environments. In <em>IJCAI,</em> pp. 918-923.</p> <p>Illanes, L., &amp; McIlraith, S. A. (2019). <strong>Generalized planning</strong> via abstraction: arbitrary numbers of objects. In <em>Proc.</em> AAAI.</p> <p>Martin, M., &amp; Geffner, H. (2004). Learning <strong>generalized policies</strong> from planning examples using concept languages. <em>Appl. Intelligence, 20</em>(1), 9-19.</p> <p>Muise, C. J., McIlraith, S. A., &amp; Beck, C. (2012). Improved non-deterministic planning by exploiting state relevance. In <em>Proc. ICAPS.</em></p> <h2 id=21>2.1. 自动规划<a class=headerlink href=#21 title="Permanent link">&para;</a></h2> <p>Geffner, H., &amp; Bonet, B. (2013). <strong>A *Concise Introduction</strong> to Models and Methods for Automated Planning.* Morgan &amp; Claypool Publishers.讲FOND问题</p> <p>Ghallab, M., Nau, D., &amp; Traverso, P. (2016). <em>Automated planning and acting.</em> CambridgeUniversity Press.</p> <h2 id=22-qnp>2.2. QNP<a class=headerlink href=#22-qnp title="Permanent link">&para;</a></h2> <p>Srivastava, S., Zilberstein, S., Immerman, N., &amp; Geffner, H. (2011). Qualitative numeric planning. In AAAI.很详细这里说FOND问题的解对应着QNP问题的解(不是互推)还有SCC算法等学长已经报告过</p> <p>Srivastava, S., Immerman, N., &amp; Zilberstein, S. (2011). A new representation and associated algorithms for <strong>Generalized planning</strong>. <em>Artificial Intelligence, 175</em>(2), 615-647.介绍QNP很有用地表述“GP通用规划”</p> <h2 id=3>3. 结合逻辑神经机<a class=headerlink href=#3 title="Permanent link">&para;</a></h2> <p>Garnelo, M., &amp; Shanahan, M. (2019). Reconciling deep learning with symbolic artificial intelligence: representing objects and relations. <em>Current Opinion in Behavioral Sciences, 29,</em> 17-23.&lt;--- <strong>将深度学习与符号人工智能相结合：表示对象和关系</strong></p> <p>Toyer, S., Trevizan, F., Thiebaux, S., &amp; Xie, L. (2018). Action schema networks: <strong>Generalised policies</strong> with deep learning. In AAAI.神经网络生成通用策略</p> <p>Groshev, E., Goldstein, M., Tamar, A., Srivastava, S., &amp; Abbeel, P. (2018). Learning generalized reactive policies using deep neural networks. In <em>Proc. ICAPS,</em> Vol. 2018, pp. 408-416.神经网络生成策略</p> <p>Fern, A., Yoon, S., &amp; Givan, R. (2004). Approximate policy iteration with a policy language bias. In <em>Advances in neural information processing systems,</em> pp. 847-854.</p> <p>Boutilier, C., Reiter, R., &amp; Price, B. (2001). Symbolic dynamic programming for first-order MDPs. In <em>Proc. IJCAI,</em> Vol. 1, pp. 690-700.一阶马尔可夫过程动态编程（我觉得**MDP**马尔可夫数学化的研究过程很明显就是无缝对接**RL**强化学习的活儿）</p> <p>Van Otterlo, M. (2012). Solving relational and first-order logical markov decision processes: A survey. In Wiering, M., &amp; van Otterlo, M. (Eds.), <em>Reinforcement Learning,</em> pp. 253-292. Springer.</p> <p>Sukhbaatar, S., Szlam, A., Synnaeve, G., Chintala, S., &amp; Fergus, R. (2015). Mazebase: A sandbox for learning from games. <em>arXiv preprint arXiv:1511.07401.</em></p> <p>Wang, C., Joshi, S., &amp; Khardon, R. (2008). First order decision diagrams for relational MDPs. <em>Journal of Artificial Intelligence Research, 31,</em> 431-472.一阶决策图对应求解MDP</p> <p>Sanner, S., &amp; Boutilier, C. (2009). Practical solution techniques for first-order MDPs. <em>Artificial Intelligence, 173</em>(5-6), 748-788.</p> <p>Nebel, B. (2000). On the compilability and expressive power of propositional planning. <em>Journal of Artificial Intelligence Research, 12, 271-315.</em></p> <p>Khardon, R. (1999). Learning action strategies for planning domains. <em>Artificial Intelligence, 113,</em> 125-148.</p> <p>Issakkimuthu, M., Fern, A., &amp; Tadepalli, P. (2018). Training deep reactive policies for probabilistic planning problems. In *ICAPS.*概率规划问题</p> <h3 id=311-sat>3.1.1. SAT<a class=headerlink href=#311-sat title="Permanent link">&para;</a></h3> <p>Een, N., &amp; Sorensson, N. (2004). An extensible SAT-solver. <em>Lecture notes in computer science, 2919,</em> 502-518.</p> <h3 id=312-complexity>3.1.2. Complexity<a class=headerlink href=#312-complexity title="Permanent link">&para;</a></h3> <p>Rintanen, J. (2004). Complexity of planning with partial observability.. In <em>Proc. ICAPS,</em> pp. 345-354.</p> <p>Levesque, H. J. (2005). Planning with loops. In <em>IJCAI,</em> pp. 509-515.指数复杂度</p> <p>Littman, M. L., Goldsmith, J., &amp; Mundhenk, M. (1998). The computational complexity of probabilistic planning. <em>Journal of Artificial Intelligence Research, 9,</em> 1-36.表明QNP问题有着指数的复杂度</p> <h2 id=32>3.2. 其他相关的论文书籍<a class=headerlink href=#32 title="Permanent link">&para;</a></h2> <p>Russell, S., &amp; Norvig, P. (2002). <em>Artificial Intelligence: A Modern Approach.</em> Prentice Hall. 2<sup>nd</sup> Edition.书籍人工智能</p> <p>Sipser, M. (2006). <em>Introduction to Theory of Computation</em> (2<sup>nd</sup> edition). Thomson Course Technology, Boston, MA.教材</p> <p>Cimatti, A., Roveri, M., &amp; Traverso, P. (1998). Automatic <strong>OBDD-based</strong> 很火的一种紧凑表达结构generation of universal plans in non-deterministic domains. In <em>Proc. AAAI-98,</em> pp. 875-881.</p> <p>Bajpai, A. N., Garg, S., et al. (2018). Transfer of deep reactive policies for mdp planning. In <em>Advances in Neural Information Processing Systems,</em> pp. 10965-10975.通用规划无限随机域</p> <p>Helmert, M. (2002). Decidability and undecidability results for planning with numerical state variables.. In <em>Proc. AIPS,</em> pp. 44-53.</p> <p>Hu, Y., &amp; De Giacomo, G. (2013). A generic technique for synthesizing bounded finite-state controllers. In <em>Proc. ICAPS.</em></p> <p>Srivastava, S., Zilberstein, S., Gupta, A., Abbeel, P., &amp; Russell, S. (2015). Tractability of planning with loops. In <em>Proc.</em> AAAI.</p> <p>Tarjan, R. (1972). Depth-first search and linear graph algorithms. <em>SIAM journal on computing, 1</em> (2), 146-160.</p> <p>Pnueli, A. (1977). The temporal logic of programs. In <em>18<sup>th</sup> Annual Symposium on Foundations of Computer Science,</em> pp. 46-57. IEEE.</p> <p>Pnueli, A., &amp; Rosner, R. (1989). On the synthesis of an asynchronous reactive module. In <em>ICALP,</em> pp. 652-671.</p></div> <footer> <div class=footer-buttons> <div class=previous><a href=../A%20review%20of%20generalized%20planning/ title=reviewOfGP><span>Previous</span></a></div> <div class=next><a href=../A%20Review%20of%20Machine%20Learning%20for%20Automated%20Planning/ title=ReviewOfMLforAP><span>Next</span></a></div> </div> <div class=footer-note> <p> Built with <a href=http://www.mkdocs.org>MkDocs</a> using <a href=https://github.com/daizutabi/mkdocs-ivory>Ivory theme</a>. </p> </div> </footer> </div> </main> </div> <script>var base_url = '../..';</script> <script src=../../js/theme.js></script> <script src=../../js/umlconvert.js></script> <script src=../../js/sequence-loader.js></script> <script src=https://unpkg.com/mermaid/dist/mermaid.min.js></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/raphael/2.3.0/raphael.min.js></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/underscore.js/1.12.0/underscore-min.js></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/js-sequence-diagrams/1.0.6/sequence-diagram-min.js></script> <script src=https://cdnjs.cloudflare.com/ajax/libs/flowchart/1.6.5/flowchart.min.js></script> <script src=../../search/main.js></script> </body> </html>